# SoC'24 [ Project ID : 102 ]: Gesture Based Text Creation aka Virtual Notedpad and recognition
Starting with Assignment-1 which is based on some basic python questions which involves numpy, matplotlib and pandas. It has 2 parts.  
Assignment-2 is the code for several activations like relu, tanh, sigmoid and also simple mlp.  
While Assignment-3 is based on training models. It has 4 parts each containing a different model.  
Then, there are some models using Handtracking Module.Like:  
BrightnessHandGesture, as the name suggests you can control the brightness of your device using hand gestures.  
DragandDrop , you use your hand gesture to drag the saved image[0(FC).jpg](0[FC].jpg) in this case.  
[Pause](Pause.py), when you run this file screen pauses when show 4 or more fingers.  
And finally, our project [VirtualNotepad](VirtualNotepad.py) provides you a canvas to draw using your hand gestures with different colours.
You can also save your canvas by pressing 's' and close the window on pressing 'q'.This model also recognises digits when you tap the 'Predict' button which uses the [mnist model](MnistModel.py)(the link of the saved model is uploaded in drive which is in [this](cnnmodel) file). The headerImages are [1.png](1.png), [2.png](2.png), [3.png](3.png), [4.png](4.png), [5.png](5.png), [6.png](6.png), [7.png](7.png), [8.png](8.png) and [9.png](9.png). On tapping the brightness icon, you can change the brightness of your device using hand gesture and on tapping the volume icon, you can change volume of your device using hand gestures.
